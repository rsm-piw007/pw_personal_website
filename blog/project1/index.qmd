---
title: "Homework 1"
author: "Pin Wang"
date: "2025-04-23"
weight: 1
callout-appearance: minimal
execute:
  python: ./.venv/bin/python  
  echo: true
  warning: false
  message: false
format:
  html:
    code-fold: true
    theme: cerulean
---

## Introduction

Dean Karlan (Yale) and John List (Chicago) conducted a large-scale direct-mail field experiment to study how matching grants affect charitable giving. They sent 50,083 prior donors one of four types of solicitation letters: a control letter (no match), or letters offering a 1:1, 2:1, or 3:1 match on donations. This notebook replicates their main findings using the publicly available Stata data.

## Data

### Load and Inspect
```{python}
import pandas as pd
# Load data
df = pd.read_stata("karlan_list_2007.dta")
# Quick overview
df.shape, df.columns
```

The dataset has 50,083 observations and variables on treatment assignment (`ratio`), donation indicator (`gave`), and donation amount (`amount`), along with covariates for balance tests.

## Balance Test

To check randomization, we compare the number of months since last donation (`mrm2`) between control and treatment groups.

```{python}
from scipy import stats
import statsmodels.formula.api as smf

# Split groups: control==1, treatment==0
grp_ctrl = df[df['control']==1]
grp_trt  = df[df['control']==0]

# T-test
t_stat, p_val = stats.ttest_ind(grp_trt['mrm2'], grp_ctrl['mrm2'], equal_var=False)
print(f"T-statistic: {t_stat:.3f}, p-value: {p_val:.3f}")
# Regression
mod = smf.ols("mrm2 ~ control", data=df).fit()
mod.summary().tables[1]
```

The t-test and regression both show no significant difference in `mrm2` (p&gt;0.05), confirming balance on this covariate. Similar checks on other demographics yield the same result, validating the random assignment.

## Experimental Results

### 1. Charitable Contribution Made

#### Response Rates Barplot
We compare the fraction of donors who gave anything in control vs. treatment.
```{python}
import matplotlib.pyplot as plt
# Compute proportions
dist = df.groupby('control')['gave'].mean().rename({1:'Control',0:'Treatment'})
dist.plot.bar(legend=False)
plt.ylabel('Proportion Gave')
plt.title('Donation Rate by Group')
plt.show()
```

#### Statistical Tests
```{python}
from scipy import stats
import statsmodels.formula.api as smf

# T-test on binary outcome
t2, p2 = stats.ttest_ind(grp_ctrl['gave'], grp_trt['gave'], equal_var=False)
print(f"Donation t-test: t={t2:.3f}, p={p2:.3f}")

# Linear regression
nmod = smf.ols('gave ~ control', data=df).fit()

# Show coefficient table
nmod.summary().tables[1]

```

Treatment increases the probability of giving by about 0.004 (0.4 percentage points), p&lt;0.01, indicating matches significantly boost participation.

#### Probit Regression
```{python}
import statsmodels.api as sm

probit = sm.Probit(df['gave'], sm.add_constant(df['control'])).fit(disp=False)
probit.summary()
```

The probit coefficient on `control` confirms a positive and significant treatment effect, matching Table 3 column 1 in Karlan & List (2007).

### 2. Differences between Match Rates

#### Pairwise T-Tests
```{python}
for r1, r2 in [(1,2),(2,3)]:
    g1 = df[df['ratio']==r1]['gave']
    g2 = df[df['ratio']==r2]['gave']
    t, p = stats.ttest_ind(g1, g2, equal_var=False)
    print(f"Ratio {r1}:1 vs {r2}:1 t={t:.3f}, p={p:.3f}")
```
No significant differences appear between 1:1 and 2:1 (p&gt;0.1) or 2:1 and 3:1 (p&gt;0.1), supporting the authors’ finding that richer matches do not further increase response.

#### Regression by Category
```{python}
mod_ratio = smf.ols('gave ~ C(ratio)', data=df).fit()
mod_ratio.summary().tables[1]
```
All match categories (1:1, 2:1, 3:1) have similar positive coefficients (~0.004) relative to control, with overlapping confidence intervals.

#### Direct and Fitted Differences
```{python}
means = df.groupby('ratio')['gave'].mean()
print("Direct diff 2:1 - 1:1:", means[2]-means[1])
print("Direct diff 3:1 - 2:1:", means[3]-means[2])
# From regression coefficients
diff12 = mod_ratio.params['C(ratio)[T.2]'] - mod_ratio.params['C(ratio)[T.1]']
print("Fitted diff 2:1 - 1:1:", diff12)
```
Both direct and fitted differences are near zero. Thus, match rate magnitude beyond 1:1 is ineffective.

### 3. Size of Charitable Contribution

#### Unconditional Amount
```{python}
tamt, pamt = stats.ttest_ind(grp_ctrl['amount'], grp_trt['amount'], equal_var=False)
print(f"Amount t-test: t={tamt:.3f}, p={pamt:.3f}")
mod_amt = smf.ols('amount ~ control', data=df).fit()
mod_amt.summary().tables[1]
```
Treatment raises average gift by about \$0.15 (p&lt;0.05).

#### Conditional on Giving
```{python}
donors = df[df['gave']==1]
cond_mod = smf.ols('amount ~ control', data=donors).fit()
cond_mod.summary().tables[1]
```
Among donors, treatment letters lead to slightly smaller average gifts (not significant), suggesting the unconditional increase is driven by higher participation rather than larger gifts.

#### Histograms
```{python}
fig, axes = plt.subplots(1,2, figsize=(10,4))
for ax, grp, title in zip(axes, [grp_ctrl, grp_trt], ['Control Donors','Treatment Donors']):
    vals = grp[grp['gave']==1]['amount']
    ax.hist(vals, bins=20)
    ax.axvline(vals.mean(), color='red')
    ax.set_title(title)
plt.tight_layout()
```

The histograms show similar distributions and means (red lines) for control and treatment donors.

## Simulation Experiment

### Law of Large Numbers

We simulate 10,000 paired draws from Bernoulli(p=0.018) and Bernoulli(p=0.022) and plot the running average of differences.

```{python}
import numpy as np
p0, p1 = 0.018, 0.022
n = 10000
d0 = np.random.binomial(1,p0,n)
d1 = np.random.binomial(1,p1,n)
diffs = d1 - d0
cum_avg = np.cumsum(diffs) / (np.arange(n)+1)
plt.plot(cum_avg)
plt.hlines(p1-p0,0,n,linestyle='--')
plt.xlabel('Iteration')
plt.ylabel('Cumulative mean difference')
plt.title('Law of Large Numbers')
```
As iterations increase, the cumulative average converges to the true difference (0.004).

### Central Limit Theorem

We generate sampling distributions of the difference in means at various sample sizes.

```{python}
n_list = [50,200,500,1000]
fig, axs = plt.subplots(2,2,figsize=(10,8))
for ax,n in zip(axs.flatten(), n_list):
    sims = []
    for i in range(1000):
        x0 = np.random.binomial(1,p0,n)
        x1 = np.random.binomial(1,p1,n)
        sims.append(x1.mean()-x0.mean())
    ax.hist(sims, bins=20)
    ax.set_title(f'n={n}')
plt.suptitle('CLT: Distribution of Mean Differences')
```

The histograms become tighter around the true mean difference (0.004) as sample size grows, illustrating the Central Limit Theorem.

---

**Conclusion**: We successfully replicate Karlan & List (2007). Matching grants boost response rates by about 0.4 percentage points, but richer matches and gift sizes remain unchanged. Simulation confirms these effects and demonstrates fundamental sampling theorems.
