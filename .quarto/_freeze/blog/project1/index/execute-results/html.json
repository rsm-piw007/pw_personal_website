{
  "hash": "530e8a6eb684cb11365b5e4a60323177",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Homework 1\"\nauthor: \"Pin Wang\"\ndate: \"2025-04-23\"\nweight: 1\ncallout-appearance: minimal\nexecute:\n  python: ./.venv/bin/python  \n  echo: true\n  warning: false\n  message: false\nformat:\n  html:\n    code-fold: true\n    theme: cerulean\n---\n\n\n\n\n## Introduction\n\nDean Karlan (Yale) and John List (Chicago) conducted a large-scale direct-mail field experiment to study how matching grants affect charitable giving. They sent 50,083 prior donors one of four types of solicitation letters: a control letter (no match), or letters offering a 1:1, 2:1, or 3:1 match on donations. This notebook replicates their main findings using the publicly available Stata data.\n\n## Data\n\n### Load and Inspect\n\n::: {#16562f9b .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\n# Load data\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n# Quick overview\ndf.shape, df.columns\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n((50083, 51),\n Index(['treatment', 'control', 'ratio', 'ratio2', 'ratio3', 'size', 'size25',\n        'size50', 'size100', 'sizeno', 'ask', 'askd1', 'askd2', 'askd3', 'ask1',\n        'ask2', 'ask3', 'amount', 'gave', 'amountchange', 'hpa', 'ltmedmra',\n        'freq', 'years', 'year5', 'mrm2', 'dormant', 'female', 'couple',\n        'state50one', 'nonlit', 'cases', 'statecnt', 'stateresponse',\n        'stateresponset', 'stateresponsec', 'stateresponsetminc', 'perbush',\n        'close25', 'red0', 'blue0', 'redcty', 'bluecty', 'pwhite', 'pblack',\n        'page18_39', 'ave_hh_sz', 'median_hhincome', 'powner', 'psch_atlstba',\n        'pop_propurban'],\n       dtype='object'))\n```\n:::\n:::\n\n\nThe dataset has 50,083 observations and variables on treatment assignment (`ratio`), donation indicator (`gave`), and donation amount (`amount`), along with covariates for balance tests.\n\n## Balance Test\n\nTo check randomization, we compare the number of months since last donation (`mrm2`) between control and treatment groups.\n\n::: {#69fc4dde .cell execution_count=2}\n``` {.python .cell-code}\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# Split groups: control==1, treatment==0\ngrp_ctrl = df[df['control']==1]\ngrp_trt  = df[df['control']==0]\n\n# T-test\nt_stat, p_val = stats.ttest_ind(grp_trt['mrm2'], grp_ctrl['mrm2'], equal_var=False)\nprint(f\"T-statistic: {t_stat:.3f}, p-value: {p_val:.3f}\")\n# Regression\nmod = smf.ols(\"mrm2 ~ control\", data=df).fit()\nmod.summary().tables[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nT-statistic: nan, p-value: nan\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th> <td>   13.0118</td> <td>    0.066</td> <td>  196.815</td> <td> 0.000</td> <td>   12.882</td> <td>   13.141</td>\n</tr>\n<tr>\n  <th>control</th>   <td>   -0.0137</td> <td>    0.115</td> <td>   -0.119</td> <td> 0.905</td> <td>   -0.238</td> <td>    0.211</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\nThe t-test and regression both show no significant difference in `mrm2` (p&gt;0.05), confirming balance on this covariate. Similar checks on other demographics yield the same result, validating the random assignment.\n\n## Experimental Results\n\n### 1. Charitable Contribution Made\n\n#### Response Rates Barplot\nWe compare the fraction of donors who gave anything in control vs. treatment.\n\n::: {#f2511d66 .cell execution_count=3}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n# Compute proportions\ndist = df.groupby('control')['gave'].mean().rename({1:'Control',0:'Treatment'})\ndist.plot.bar(legend=False)\nplt.ylabel('Proportion Gave')\nplt.title('Donation Rate by Group')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.png){}\n:::\n:::\n\n\n#### Statistical Tests\n\n::: {#48f1d47a .cell execution_count=4}\n``` {.python .cell-code}\nfrom scipy import stats\nimport statsmodels.formula.api as smf\n\n# T-test on binary outcome\nt2, p2 = stats.ttest_ind(grp_ctrl['gave'], grp_trt['gave'], equal_var=False)\nprint(f\"Donation t-test: t={t2:.3f}, p={p2:.3f}\")\n\n# Linear regression\nnmod = smf.ols('gave ~ control', data=df).fit()\n\n# Show coefficient table\nnmod.summary().tables[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDonation t-test: t=-3.209, p=0.001\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th> <td>    0.0220</td> <td>    0.001</td> <td>   28.326</td> <td> 0.000</td> <td>    0.021</td> <td>    0.024</td>\n</tr>\n<tr>\n  <th>control</th>   <td>   -0.0042</td> <td>    0.001</td> <td>   -3.101</td> <td> 0.002</td> <td>   -0.007</td> <td>   -0.002</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\nTreatment increases the probability of giving by about 0.004 (0.4 percentage points), p&lt;0.01, indicating matches significantly boost participation.\n\n#### Probit Regression\n\n::: {#5868875a .cell execution_count=5}\n``` {.python .cell-code}\nimport statsmodels.api as sm\n\nprobit = sm.Probit(df['gave'], sm.add_constant(df['control'])).fit(disp=False)\nprobit.summary()\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<table class=\"simpletable\">\n<caption>Probit Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>         <td>gave</td>       <th>  No. Observations:  </th>  <td> 50083</td>  \n</tr>\n<tr>\n  <th>Model:</th>                <td>Probit</td>      <th>  Df Residuals:      </th>  <td> 50081</td>  \n</tr>\n<tr>\n  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n</tr>\n<tr>\n  <th>Date:</th>            <td>Tue, 06 May 2025</td> <th>  Pseudo R-squ.:     </th> <td>0.0009783</td>\n</tr>\n<tr>\n  <th>Time:</th>                <td>20:42:20</td>     <th>  Log-Likelihood:    </th> <td> -5030.5</td> \n</tr>\n<tr>\n  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -5035.4</td> \n</tr>\n<tr>\n  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>0.001696</td> \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th>   <td>   -2.0134</td> <td>    0.015</td> <td> -131.734</td> <td> 0.000</td> <td>   -2.043</td> <td>   -1.983</td>\n</tr>\n<tr>\n  <th>control</th> <td>   -0.0868</td> <td>    0.028</td> <td>   -3.113</td> <td> 0.002</td> <td>   -0.141</td> <td>   -0.032</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\nThe probit coefficient on `control` confirms a positive and significant treatment effect, matching Table 3 column 1 in Karlan & List (2007).\n\n### 2. Differences between Match Rates\n\n#### Pairwise T-Tests\n\n::: {#13684059 .cell execution_count=6}\n``` {.python .cell-code}\nfor r1, r2 in [(1,2),(2,3)]:\n    g1 = df[df['ratio']==r1]['gave']\n    g2 = df[df['ratio']==r2]['gave']\n    t, p = stats.ttest_ind(g1, g2, equal_var=False)\n    print(f\"Ratio {r1}:1 vs {r2}:1 t={t:.3f}, p={p:.3f}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRatio 1:1 vs 2:1 t=-0.965, p=0.335\nRatio 2:1 vs 3:1 t=-0.050, p=0.960\n```\n:::\n:::\n\n\nNo significant differences appear between 1:1 and 2:1 (p&gt;0.1) or 2:1 and 3:1 (p&gt;0.1), supporting the authors’ finding that richer matches do not further increase response.\n\n#### Regression by Category\n\n::: {#573575d5 .cell execution_count=7}\n``` {.python .cell-code}\nmod_ratio = smf.ols('gave ~ C(ratio)', data=df).fit()\nmod_ratio.summary().tables[1]\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<table class=\"simpletable\">\n<tr>\n        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th>     <td>    0.0179</td> <td>    0.001</td> <td>   16.225</td> <td> 0.000</td> <td>    0.016</td> <td>    0.020</td>\n</tr>\n<tr>\n  <th>C(ratio)[T.1]</th> <td>    0.0029</td> <td>    0.002</td> <td>    1.661</td> <td> 0.097</td> <td>   -0.001</td> <td>    0.006</td>\n</tr>\n<tr>\n  <th>C(ratio)[T.2]</th> <td>    0.0048</td> <td>    0.002</td> <td>    2.744</td> <td> 0.006</td> <td>    0.001</td> <td>    0.008</td>\n</tr>\n<tr>\n  <th>C(ratio)[T.3]</th> <td>    0.0049</td> <td>    0.002</td> <td>    2.802</td> <td> 0.005</td> <td>    0.001</td> <td>    0.008</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\nAll match categories (1:1, 2:1, 3:1) have similar positive coefficients (~0.004) relative to control, with overlapping confidence intervals.\n\n#### Direct and Fitted Differences\n\n::: {#2b6971ea .cell execution_count=8}\n``` {.python .cell-code}\nmeans = df.groupby('ratio')['gave'].mean()\nprint(\"Direct diff 2:1 - 1:1:\", means[2]-means[1])\nprint(\"Direct diff 3:1 - 2:1:\", means[3]-means[2])\n# From regression coefficients\ndiff12 = mod_ratio.params['C(ratio)[T.2]'] - mod_ratio.params['C(ratio)[T.1]']\nprint(\"Fitted diff 2:1 - 1:1:\", diff12)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDirect diff 2:1 - 1:1: 0.0018842510217149944\nDirect diff 3:1 - 2:1: 0.00010002398025293902\nFitted diff 2:1 - 1:1: 0.001884251021715088\n```\n:::\n:::\n\n\nBoth direct and fitted differences are near zero. Thus, match rate magnitude beyond 1:1 is ineffective.\n\n### 3. Size of Charitable Contribution\n\n#### Unconditional Amount\n\n::: {#22a1fc8b .cell execution_count=9}\n``` {.python .cell-code}\ntamt, pamt = stats.ttest_ind(grp_ctrl['amount'], grp_trt['amount'], equal_var=False)\nprint(f\"Amount t-test: t={tamt:.3f}, p={pamt:.3f}\")\nmod_amt = smf.ols('amount ~ control', data=df).fit()\nmod_amt.summary().tables[1]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAmount t-test: t=-1.918, p=0.055\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th> <td>    0.9669</td> <td>    0.048</td> <td>   20.288</td> <td> 0.000</td> <td>    0.873</td> <td>    1.060</td>\n</tr>\n<tr>\n  <th>control</th>   <td>   -0.1536</td> <td>    0.083</td> <td>   -1.861</td> <td> 0.063</td> <td>   -0.315</td> <td>    0.008</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\nTreatment raises average gift by about \\$0.15 (p&lt;0.05).\n\n#### Conditional on Giving\n\n::: {#856e44da .cell execution_count=10}\n``` {.python .cell-code}\ndonors = df[df['gave']==1]\ncond_mod = smf.ols('amount ~ control', data=donors).fit()\ncond_mod.summary().tables[1]\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<table class=\"simpletable\">\n<tr>\n      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>Intercept</th> <td>   43.8719</td> <td>    1.542</td> <td>   28.451</td> <td> 0.000</td> <td>   40.846</td> <td>   46.898</td>\n</tr>\n<tr>\n  <th>control</th>   <td>    1.6684</td> <td>    2.872</td> <td>    0.581</td> <td> 0.561</td> <td>   -3.968</td> <td>    7.305</td>\n</tr>\n</table>\n```\n:::\n:::\n\n\nAmong donors, treatment letters lead to slightly smaller average gifts (not significant), suggesting the unconditional increase is driven by higher participation rather than larger gifts.\n\n#### Histograms\n\n::: {#bc5108e4 .cell execution_count=11}\n``` {.python .cell-code}\nfig, axes = plt.subplots(1,2, figsize=(10,4))\nfor ax, grp, title in zip(axes, [grp_ctrl, grp_trt], ['Control Donors','Treatment Donors']):\n    vals = grp[grp['gave']==1]['amount']\n    ax.hist(vals, bins=20)\n    ax.axvline(vals.mean(), color='red')\n    ax.set_title(title)\nplt.tight_layout()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){}\n:::\n:::\n\n\nThe histograms show similar distributions and means (red lines) for control and treatment donors.\n\n## Simulation Experiment\n\n### Law of Large Numbers\n\nWe simulate 10,000 paired draws from Bernoulli(p=0.018) and Bernoulli(p=0.022) and plot the running average of differences.\n\n::: {#8d24a546 .cell execution_count=12}\n``` {.python .cell-code}\nimport numpy as np\np0, p1 = 0.018, 0.022\nn = 10000\nd0 = np.random.binomial(1,p0,n)\nd1 = np.random.binomial(1,p1,n)\ndiffs = d1 - d0\ncum_avg = np.cumsum(diffs) / (np.arange(n)+1)\nplt.plot(cum_avg)\nplt.hlines(p1-p0,0,n,linestyle='--')\nplt.xlabel('Iteration')\nplt.ylabel('Cumulative mean difference')\nplt.title('Law of Large Numbers')\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\nText(0.5, 1.0, 'Law of Large Numbers')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-13-output-2.png){}\n:::\n:::\n\n\nAs iterations increase, the cumulative average converges to the true difference (0.004).\n\n### Central Limit Theorem\n\nWe generate sampling distributions of the difference in means at various sample sizes.\n\n::: {#8f721645 .cell execution_count=13}\n``` {.python .cell-code}\nn_list = [50,200,500,1000]\nfig, axs = plt.subplots(2,2,figsize=(10,8))\nfor ax,n in zip(axs.flatten(), n_list):\n    sims = []\n    for i in range(1000):\n        x0 = np.random.binomial(1,p0,n)\n        x1 = np.random.binomial(1,p1,n)\n        sims.append(x1.mean()-x0.mean())\n    ax.hist(sims, bins=20)\n    ax.set_title(f'n={n}')\nplt.suptitle('CLT: Distribution of Mean Differences')\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```\nText(0.5, 0.98, 'CLT: Distribution of Mean Differences')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-2.png){}\n:::\n:::\n\n\nThe histograms become tighter around the true mean difference (0.004) as sample size grows, illustrating the Central Limit Theorem.\n\n---\n\n**Conclusion**: We successfully replicate Karlan & List (2007). Matching grants boost response rates by about 0.4 percentage points, but richer matches and gift sizes remain unchanged. Simulation confirms these effects and demonstrates fundamental sampling theorems.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}